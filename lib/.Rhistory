Movie_rated_by_u<-train[train$userId == u,]$movieId%>%unique%>%as.character()
Movie_NOTrated_by_u<-Movie_all[!Movie_all%in%Movie_rated_by_u]
Rating_by_u<-R[u,]
for (i in Movie_NOTrated_by_u){
tmp<-distance_movie[i,Movie_rated_by_u]%>%which.max%>%names
Rating_by_u[i]<-Rating_by_u[tmp]
}
R[u,]<-Rating_by_u
}
return(rating_knn=R)
}
KNN_Rating<-KNN.post(resultr12)
Rating<-t(resultr12$p)%*%(resultr12$q)
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
tibble(rating=c("w/o knn","w/  knn"),
train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),
test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
library(tidyverse)
library(caret)
library(parallel)
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
minFunc <- function(rating, matSolv, lambda){
solve(matSolv %*% t(matSolv) + lambda * diag(f)) %*% matSolv %*% rating
}
# The Function used to Find the
findSolve <- function(id, solveBy, train, lambda){
id <- as.integer(id)
# Fix Movies, solve User
if(solveBy=="Movies"){
movId <- train[train$userId==id, ]$movieId
movSolv <- Movies[, as.character(movId)]
rating <- train[train$userId==id, ]$rating
minFunc(rating = rating, matSolv = movSolv, lambda = lambda)
}
# Fix User, solve Movie
else if(solveBy=="Users"){
userId <- train[train$movieId==id, ]$userId
userSolv <- Users[, as.character(userId)]
rating <- train[train$movieId==id, ]$rating
minFunc(rating = rating, matSolv = userSolv, lambda = lambda)
}
else return("Please let matSolv be in right way")
}
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(1)
# train-test split (.8/.2)
train_ind <- createDataPartition(data$userId, p=.8, list=F)
train <- data[train_ind, ]
test <- data[-train_ind, ]
ALS <- function(data, train, test, f, maxIters, lambda=5){
# Factorized the Movies and User matrices
UserId <- unique(data$userId)
U <- length(UserId)
MovieId <- unique(data$movieId)
M <- length(MovieId)
avgRatingByUser <- data %>%
group_by(userId) %>%
summarise(avgRating = mean(rating))
avgRatingByMovie <- data %>%
group_by(movieId) %>%
summarise(avgRating = mean(rating))
Users <- matrix(c(avgRatingByUser$avgRating, runif((f-1)*U, -1, 1)), nrow=f, byrow = T)
colnames(Users) <- UserId
Movies <- matrix(c(avgRatingByMovie$avgRating, rnorm((f-1)*M, -1, 1)), nrow=f, byrow = T)
colnames(Movies) <- MovieId
clusterExport(cl, "minFunc", envir = environment())
clusterExport(cl, "f", envir = environment())
clusterExport(cl, "UserId", envir = environment())
clusterExport(cl, "MovieId", envir = environment())
trainRMSE <- rep(NA, maxIters%/%3)
testRMSE <- rep(NA, maxIters%/%3)
iter <- 1
while(iter <= maxIters){
st <- Sys.time()
# Fix Movie, solve User
clusterExport(cl, "Movies", envir = environment())
clusterExport(cl, "Users", envir = environment())
Users <- parSapply(cl, as.character(UserId), findSolve, solveBy="Movies", train = train, lambda = lambda, USE.NAMES = T)
# Fix User, solve Movie
clusterExport(cl, "Movies", envir = environment())
clusterExport(cl, "Users", envir = environment())
Movies <- parSapply(cl, as.character(MovieId), findSolve, solveBy="Users", train = train, lambda = lambda, USE.NAMES = T)
# cat("Iter:", iter,  "\t Time spent:", round(Sys.time()-st, 3), "s\n")
# if(iter%%3==1){
#   est_rating <- t(Users) %*% Movies
#
#   trainRMSE[iter%/%3+1] <- RMSE(train, est_rating)
#   testRMSE[iter%/%3+1] <- RMSE(test, est_rating)
# }
cat(".")
if(iter==maxIters) cat("\n")
iter <- iter + 1
}
# RMSE
est_rating <- t(Users) %*% Movies
trainRMSE <- RMSE(train, est_rating)
testRMSE <- RMSE(test, est_rating)
return(list("User" = Users,
"Movie" = Movies,
"Rating" = est_rating,
"TrainRMSE" = trainRMSE,
"TestRMSE" = testRMSE))
}
source("../lib/cross_validation.R")
source("../lib/P3.R")
fs <- c(5, 10, 15)
lambdas_als <- c(1, 5,10)
lambdas_P <- c(1, 5, 10)
sigmas <- c(1,2,3)
cv.df <- expand.grid("fs"=fs,
"lambdas_als"=lambdas_als,
"lambdas_p"=lambdas_P,
"sigmas" =sigmas)
ALS_KRR <- function(data, train, test, f, maxIters, lambda_als, lambda_p, sigma){
# data=dat_train
# train=train.data
# test=test.data
# f=f
# maxIters=maxIter
# lambda=lambdas_als
# lambda_p=lambdas_p
# sigma=sigmas
result_ALS <- ALS(data, train, test, f, maxIters, lambda_als)
KRR.Post(result_ALS=result_ALS,lambda=lambda_p, sigma=sigma, data, train, test)
}
cl <- makeCluster(8)
cl <- makeCluster(8)
load( file="../output/cvtmp.RData")
for (i in 47:dim(x)[1]){
tmp=cv.functionYQ(dat_train = data,K=5,f=x[i,]$fs,maxIter =15,lambdas_als = x[i,]$lambdas_als,lambdas_p = x[i,]$lambdas_p,sigmas =  x[i,]$sigmas)
x[i,"train_mean"]=tmp$mean_train_rmse
x[i,"test_mean"]=tmp$mean_test_rmse
# x[i,"train_sd"]=tmp$sd_train_rmse
# x[i,"test_sd"]=tmp$sd_test_rmse
rm(tmp)
}
library(tidyverse)
library(caret)
library(parallel)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(1)
# train-test split (.8/.2)
train_ind <- createDataPartition(data$userId, p=.8, list=F)
train <- data[train_ind, ]
test <- data[-train_ind, ]
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
minFunc <- function(rating, matSolv, lambda){
solve(matSolv %*% t(matSolv) + lambda * diag(f)) %*% matSolv %*% rating
}
# The Function used to Find the
findSolve <- function(id, solveBy, train, lambda){
id <- as.integer(id)
# Fix Movies, solve User
if(solveBy=="Movies"){
movId <- train[train$userId==id, ]$movieId
movSolv <- Movies[, as.character(movId)]
rating <- train[train$userId==id, ]$rating
minFunc(rating = rating, matSolv = movSolv, lambda = lambda)
}
# Fix User, solve Movie
else if(solveBy=="Users"){
userId <- train[train$movieId==id, ]$userId
userSolv <- Users[, as.character(userId)]
rating <- train[train$movieId==id, ]$rating
minFunc(rating = rating, matSolv = userSolv, lambda = lambda)
}
else return("Please let matSolv be in right way")
}
ALS <- function(data, train, test, f, maxIters, lambda=5){
# Factorized the Movies and User matrices
UserId <- unique(data$userId)
U <- length(UserId)
MovieId <- unique(data$movieId)
M <- length(MovieId)
avgRatingByUser <- data %>%
group_by(userId) %>%
summarise(avgRating = mean(rating))
avgRatingByMovie <- data %>%
group_by(movieId) %>%
summarise(avgRating = mean(rating))
Users <- matrix(c(avgRatingByUser$avgRating, runif((f-1)*U, -1, 1)), nrow=f, byrow = T)
colnames(Users) <- UserId
Movies <- matrix(c(avgRatingByMovie$avgRating, rnorm((f-1)*M, -1, 1)), nrow=f, byrow = T)
colnames(Movies) <- MovieId
clusterExport(cl, "minFunc", envir = environment())
clusterExport(cl, "f", envir = environment())
clusterExport(cl, "UserId", envir = environment())
clusterExport(cl, "MovieId", envir = environment())
trainRMSE <- rep(NA, maxIters%/%3)
testRMSE <- rep(NA, maxIters%/%3)
iter <- 1
while(iter <= maxIters){
st <- Sys.time()
# Fix Movie, solve User
clusterExport(cl, "Movies", envir = environment())
clusterExport(cl, "Users", envir = environment())
Users <- parSapply(cl, as.character(UserId), findSolve, solveBy="Movies", train = train, lambda = lambda, USE.NAMES = T)
# Fix User, solve Movie
clusterExport(cl, "Movies", envir = environment())
clusterExport(cl, "Users", envir = environment())
Movies <- parSapply(cl, as.character(MovieId), findSolve, solveBy="Users", train = train, lambda = lambda, USE.NAMES = T)
# cat("Iter:", iter,  "\t Time spent:", round(Sys.time()-st, 3), "s\n")
# if(iter%%3==1){
#   est_rating <- t(Users) %*% Movies
#
#   trainRMSE[iter%/%3+1] <- RMSE(train, est_rating)
#   testRMSE[iter%/%3+1] <- RMSE(test, est_rating)
# }
cat(".")
if(iter==maxIters) cat("\n")
iter <- iter + 1
}
# RMSE
est_rating <- t(Users) %*% Movies
trainRMSE <- RMSE(train, est_rating)
testRMSE <- RMSE(test, est_rating)
return(list("User" = Users,
"Movie" = Movies,
"Rating" = est_rating,
"TrainRMSE" = trainRMSE,
"TestRMSE" = testRMSE))
}
# # set the number of cores to use
# cl <- makeCluster(8)
# result <- ALS(data, train, test, f = 10, maxIters = 15, lambda = 1)
# stopCluster(cl)
source("../lib/cross_validation.R")
source("../lib/P3.R")
fs <- c(5, 10, 15)
lambdas_als <- c(1, 5,10)
lambdas_P <- c(1, 5, 10)
sigmas <- c(1,2,3)
cv.df <- expand.grid("fs"=fs,
"lambdas_als"=lambdas_als,
"lambdas_p"=lambdas_P,
"sigmas" =sigmas)
ALS_KRR <- function(data, train, test, f, maxIters, lambda_als, lambda_p, sigma){
# data=dat_train
# train=train.data
# test=test.data
# f=f
# maxIters=maxIter
# lambda=lambdas_als
# lambda_p=lambdas_p
# sigma=sigmas
result_ALS <- ALS(data, train, test, f, maxIters, lambda_als)
KRR.Post(result_ALS=result_ALS,lambda=lambda_p, sigma=sigma, data, train, test)
}
cl <- makeCluster(8)
load( file="../output/cvtmp.RData")
# x=cv.df%>%as_tibble()%>%mutate(train_mean=NA,test_mean=NA,train_sd=NA,test_sd=NA)#%>%head(2)
# x=cv.df%>%as_tibble()%>%mutate(train_mean=NA,test_mean=NA)
for (i in 47:dim(x)[1]){
tmp=cv.functionYQ(dat_train = data,K=5,f=x[i,]$fs,maxIter =15,lambdas_als = x[i,]$lambdas_als,lambdas_p = x[i,]$lambdas_p,sigmas =  x[i,]$sigmas)
x[i,"train_mean"]=tmp$mean_train_rmse
x[i,"test_mean"]=tmp$mean_test_rmse
# x[i,"train_sd"]=tmp$sd_train_rmse
# x[i,"test_sd"]=tmp$sd_test_rmse
rm(tmp)
}
save(x, file="../output/cvtmp.RData")
x[81,]
source("../lib/ALSwithP3.R")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(e1071)
train_5 <- read_csv("train_5.txt")%>%as_tibble()
train_6 <- read_csv("train_6.txt")%>%as_tibble()
train_5$label=rep(-1, nrow(train_5))
train_6$label=rep (1 , nrow(train_6))
names(train_6)=names(train_5)
data= rbind(train_5, train_6)
data$label=as.factor(data$label)
index= sample (1: nrow (data), 0.8*nrow (data))
train_data = data[index, ]
test_data = data[-index , ]
train_x=train_data%>%select(-label)
train_y=train_data%>%select(label)
test_x=test_data%>%select(-label)
test_y=test_data%>%select(label)
tc <- tune.control(cross = 5)
cost=c(0.0001,0.01,0.1,1,10,50)
obj2=tune.svm(label~.,data=train_data,cost=cost,scale=F,tunecontrol = tc)
obj2$best.parameters
gamma=c(0.1,0.01,0.005)
obj3=tune.svm(label~.,data=train_data,cost=cost,gamma=gamma,scale=F,tunecontrol = tc)
train_5 <- read_csv("train_5.txt")%>%as_tibble()
train_6 <- read_csv("train_6.txt")%>%as_tibble()
train_5$label=rep(-1, nrow(train_5))
train_6$label=rep (1 , nrow(train_6))
names(train_6)=names(train_5)
data= rbind(train_5, train_6)
data$label=as.factor(data$label)
index= sample (1: nrow (data), 0.8*nrow (data))
train_data = data[index, ]
test_data = data[-index , ]
train_x=train_data%>%select(-label)
train_y=train_data%>%select(label)
test_x=test_data%>%select(-label)
test_y=test_data%>%select(label)
my.lasso <- function(data, lambda){
# data prepared
n <- nrow(data)
p <- ncol(data) - 1
X <- as.matrix(data[, 1:p])
y <- data[, p+1]
X_s <- X %>%scale()
X_sd <- apply(X, 2, sd)
X_mean <- apply(X, 2, mean)
y_c <- c(data[, p+1]) %>% scale(scale=F)
y_mean <- mean(y)
max_iter <- 300
beta <- c(rnorm(p, 0, .1))
# functions used
sto <- function(x, lambda){
if(x > lambda) x -lambda
else if(x < -lambda) x + lambda
else 0
}
sigmoid <- function(x){1 - 1/(1+exp(x))}
get_beta <- function(beta, n, X, y, lambda){
y_h <- sigmoid(X%*%beta)
beta_n <- beta + 1/n * t(X) %*% (y - y_h)
sapply(beta_n, sto, lambda=lambda)
}
# beta
for(i in 1:max_iter){
beta <- get_beta(beta, n, X_s, y_c, lambda)
}
betas <- beta/X_sd
beta0 <- y_mean - (X_mean)%*%betas
list("beta_0"=beta0, "beta"=betas)
}
# lasso in glmnet
gml.model <- glmnet(x=as.matrix(my.lasso.data[,1:10]),
y=my.lasso.data[,11],
family="binomial",
alpha = 1,
intercept=T,
lambda=.05)
library(tidyverse)
library(e1071)
library("Matrix")
library("glmnet")
library(readr)
train_5 <- read_csv("train_5.txt")%>%as_tibble()
train_6 <- read_csv("train_6.txt")%>%as_tibble()
train_5$label=rep(0, nrow(train_5))
train_6$label=rep (1 , nrow(train_6))
train_5 <- read_csv("train_5.txt")%>%as_tibble()
train_6 <- read_csv("train_6.txt")%>%as_tibble()
train_5$label=rep(-1, nrow(train_5))
train_6$label=rep (1 , nrow(train_6))
names(train_6)=names(train_5)
data= rbind(train_5, train_6)
data$label=as.factor(data$label)
index= sample (1: nrow (data), 0.8*nrow (data))
train_data = data[index, ]
test_data = data[-index , ]
train_x=train_data%>%select(-label)
train_y=train_data%>%select(label)
test_x=test_data%>%select(-label)
test_y=test_data%>%select(label)
train_5 <- read_csv("train_5.txt")%>%as_tibble()
train_6 <- read_csv("train_6.txt")%>%as_tibble()
train_5$label=rep(0, nrow(train_5))
train_6$label=rep (1 , nrow(train_6))
my.lasso <- function(data, lambda){
# data prepared
n <- nrow(data)
p <- ncol(data) - 1
X <- as.matrix(data[, 1:p])
y <- data[, p+1]
X_s <- X %>%scale()
X_sd <- apply(X, 2, sd)
X_mean <- apply(X, 2, mean)
y_c <- c(data[, p+1]) %>% scale(scale=F)
y_mean <- mean(y)
max_iter <- 300
beta <- c(rnorm(p, 0, .1))
# functions used
sto <- function(x, lambda){
if(x > lambda) x -lambda
else if(x < -lambda) x + lambda
else 0
}
sigmoid <- function(x){1 - 1/(1+exp(x))}
get_beta <- function(beta, n, X, y, lambda){
y_h <- sigmoid(X%*%beta)
beta_n <- beta + 1/n * t(X) %*% (y - y_h)
sapply(beta_n, sto, lambda=lambda)
}
# beta
for(i in 1:max_iter){
beta <- get_beta(beta, n, X_s, y_c, lambda)
}
betas <- beta/X_sd
beta0 <- y_mean - (X_mean)%*%betas
list("beta_0"=beta0, "beta"=betas)
}
# lasso in glmnet
my.lasso.data <- read.csv(file= "LogisticLasso.csv")
# lasso in glmnet
my.lasso.data <- read.csv(file= "LogisticLasso.csv")
gml.model <- glmnet(x=as.matrix(my.lasso.data[,1:10]),
y=my.lasso.data[,11],
family="binomial",
alpha = 1,
intercept=T,
lambda=.05)
gml.my.model <- my.lasso(my.lasso.data, lambda=.05)
train_5 <- read_csv("train_5.txt")%>%as_tibble()
train_6 <- read_csv("train_6.txt")%>%as_tibble()
train_5$label=rep(0, nrow(train_5))
train_6$label=rep (1 , nrow(train_6))
data <- rbind(train_5,train_6)
train_5 <- read_csv("train_5.txt")%>%as_tibble()
train_6 <- read_csv("train_6.txt")%>%as_tibble()
train_5$label=rep(0, nrow(train_5))
train_6$label=rep (1 , nrow(train_6))
names(train_6)=names(train_5)
data= rbind(train_5, train_6)
data <- rbind(train_5,train_6)
data_5 <- read.table("train_5.txt", header=F, sep=",") %>%
cbind("Labels"=-1)
data_6 <- read.table("train_6.txt", header=F, sep=",") %>%
cbind("Labels"=1)
data= rbind(data_5, data_6)
data$label=as.factor(data$label)
index= sample (1: nrow (data), 0.8*nrow (data))
data_5 <- read.table("train_5.txt", header=F, sep=",") %>%
cbind("label"=-1)
data_6 <- read.table("train_6.txt", header=F, sep=",") %>%
cbind("label"=1)
data= rbind(data_5, data_6)
data$label=as.factor(data$label)
index= sample (1: nrow (data), 0.8*nrow (data))
train_data = data[index, ]
test_data = data[-index , ]
train_x=train_data%>%select(-label)
train_y=train_data%>%select(label)
test_x=test_data%>%select(-label)
test_y=test_data%>%select(label)
data_5 <- read.table("train_5.txt", header=F, sep=",") %>%
cbind("label"=0)
data_6 <- read.table("train_6.txt", header=F, sep=",") %>%
cbind("label"=1)
data= rbind(data_5, data_6)
my.lasso <- function(data, lambda){
# data prepared
n <- nrow(data)
p <- ncol(data) - 1
X <- as.matrix(data[, 1:p])
y <- data[, p+1]
X_s <- X %>%scale()
X_sd <- apply(X, 2, sd)
X_mean <- apply(X, 2, mean)
y_c <- c(data[, p+1]) %>% scale(scale=F)
y_mean <- mean(y)
max_iter <- 300
beta <- c(rnorm(p, 0, .1))
# functions used
sto <- function(x, lambda){
if(x > lambda) x -lambda
else if(x < -lambda) x + lambda
else 0
}
sigmoid <- function(x){1 - 1/(1+exp(x))}
get_beta <- function(beta, n, X, y, lambda){
y_h <- sigmoid(X%*%beta)
beta_n <- beta + 1/n * t(X) %*% (y - y_h)
sapply(beta_n, sto, lambda=lambda)
}
# beta
for(i in 1:max_iter){
beta <- get_beta(beta, n, X_s, y_c, lambda)
}
betas <- beta/X_sd
beta0 <- y_mean - (X_mean)%*%betas
list("beta_0"=beta0, "beta"=betas)
}
# lasso in glmnet
my.lasso.data <- read.csv(file= "LogisticLasso.csv")
gml.model <- glmnet(x=as.matrix(my.lasso.data[,1:10]),
y=my.lasso.data[,11],
family="binomial",
alpha = 1,
intercept=T,
lambda=.05)
gml.my.model <- my.lasso(my.lasso.data, lambda=.05)
cat("glmnet model: \n")
c(gml.model$a0,gml.model$beta[,1])
cat("\nmy model: \n")
c(gml.my.model$beta_0, gml.my.model$beta)
