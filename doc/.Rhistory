n <- nrow(data.x)
cv.id <- createFolds(1:n, k = kfold)
cv.tuning <- c()
for (j in cv.id){
#Split Data in train and validation sets
x.train.cv <- data.x[-j,]
y.train.cv <- data.y[-j]
x.validation.cv <- data.x[j,]
y.validation.cv <- data.y[j]
#Run Model
mod.cv <- krr(x = x.train.cv,  y.train.cv, lambda = lam)
#Estimate predictin of validation test
pred.cv <- predict(mod.cv, x.validation.cv)
#Calculate RMSE
rmse.cv <- sqrt(mean((y.validation.cv - pred.cv)^2))
cv.tuning <- cbind(cv.tuning, rmse.cv)
cv.mean <- mean(cv.tuning)
}
return(cv.mean)
}
#find a best lambda
lambdas <- c(0.7)
rmse_tune <- data.frame(lambdas=lambdas,rmse=rep(0,length(lambdas)))
for (i in 1:length(lambdas)){
m <- lapply(data_split, cv.krr, 5, lambdas[i])
rmse_tune[i,2] <-  sum(unlist(m))
}
#use tuned lambda to train 610 users model
train_model<-vector(mode="list",length=length(data_split))
for(i in 1:length(data_split)){
train_model[[i]]<-krr(data_split[[i]][,-1],data_split[[i]][,1],0.7)}
train
length(data_split)
i=1
train_model[[i]]<-krr(data_split[[i]][,-1],data_split[[i]][,1],0.7)}
#use tuned lambda to train 610 users model
train_model<-vector(mode="list",length=length(data_split))
for(i in 1:length(data_split)){
train_model[[i]]<-krr(data_split[[i]][,-1],data_split[[i]][,1],0.7)}
q%>%dim()
train_set<-train
test_set<-test
q<-resultALS$User
rating.a3<-resultALS$Rating
q%>%dim()
#data transformation and get input of krr
train_split<-split(train_set,train_set$userId)
train_split1<-split(train_set,train_set$movieId)
length(train_split1)
q[1,]
q
View(q)
train$movieId%>%unique()
train$movieId%>%unique()%>%sort
# length(train_split1) #***
# movie<-as.vector(unlist(c(q[1,]))) #***
movie<-train$movieId%>%unique()%>%sort
# q<-as.matrix(q[-1,])
q<-as.matrix(q)
train_split<-split(train_set,train_set$userId)
train_split1<-split(train_set,train_set$movieId)
# length(train_split1) #***
# movie<-as.vector(unlist(c(q[1,]))) #***
movie<-train$movieId%>%unique()%>%sort
# q<-as.matrix(q[-1,])
q<-as.matrix(q)
new_q_split<-list()
train_split
train_split[[1]]
train_split[[1]][1]
dim(train_split[[1]])
new_q_split<-list()
for (k in 1:length(train_split)){
new<-c()
for (i in 1:dim(train_split[[k]])[1]){
new<-cbind(new,q[,which(movie==train_split[[k]]$movieId[i])])}
new_q_split[[k]]<-new}
k=1
new<-c()
i=1
new<-cbind(new,q[,which(movie==train_split[[k]]$movieId[i])])
new<-c()
for (i in 1:dim(train_split[[k]])[1]){
new<-cbind(new,q[,which(movie==train_split[[k]]$movieId[i])])
}
k=1
i=1
for (i in 1:dim(train_split[[k]])[1]){
new<-cbind(new,q[,which(movie==train_split[[k]]$movieId[i])])
print(i)
}
i=34
new<-c()
new<-cbind(new,q[,which(movie==train_split[[k]]$movieId[i])])
i=35
new<-cbind(new,q[,which(movie==train_split[[k]]$movieId[i])])
q[,which(movie==train_split[[k]]$movieId[i])]
which(movie==train_split[[k]]$movieId[i])
# length(train_split1) #***
# movie<-as.vector(unlist(c(q[1,]))) #***
movie<-train_set$movieId%>%unique()%>%sort
# q<-as.matrix(q[-1,])
q<-as.matrix(q)
movie
length(movie)
dim(q)
q<-resultALS$Movie
#read output and data
# train_set<-read.csv("../data/train_set.csv")
# test_set<-read.csv("../data/test_set.csv")
# q<-read.csv("../output/A3_q_dim10.csv",header= FALSE)
# rating.a3<-read.csv("../output/A3_r_dim10.csv",header=FALSE)
train_set<-train
test_set<-test
q<-resultALS$Movie
rating.a3<-resultALS$Rating
train_split<-split(train_set,train_set$userId)
train_split1<-split(train_set,train_set$movieId)
# movie<-as.vector(unlist(c(q[1,]))) #***
movie<-train_set$movieId%>%unique()%>%sort
# q<-as.matrix(q[-1,])
q<-as.matrix(q)
new_q_split<-list()
for (k in 1:length(train_split)){
new<-c()
for (i in 1:dim(train_split[[k]])[1]){
new<-cbind(new,q[,which(movie==train_split[[k]]$movieId[i])])
print(i)
}
new_q_split[[k]]<-new
}
movie<-train_set$movieId%>%unique()%>%sort
# q<-as.matrix(q[-1,])
q<-as.matrix(q)
new_q_split<-list()
for (k in 1:length(train_split)){
new<-c()
for (i in 1:dim(train_split[[k]])[1]){
new<-cbind(new,q[,which(movie==train_split[[k]]$movieId[i])])
}
new_q_split[[k]]<-new
}
normal<-function(a){return(a/sqrt(sum(a^2)))}
q_trans<-apply(q,2,normal)
q_trans[which(is.na(q_trans))]<-0
x_split<-list()
for (k in 1:length(train_split)){
x_split[[k]]<-apply(new_q_split[[k]],2,normal)}
data_split<-list()
for (k in 1:length(train_split)){
data_split[[k]]<-cbind(train_split[[k]]$rating,t(x_split[[k]]))}
#write a function to do cross validation for parameter lambda in krr
cv.krr <- function(data, kfold, lam){
set.seed(123)
data.x <- as.matrix(data[,-1])
data.y <- data[,1]
n <- nrow(data.x)
cv.id <- createFolds(1:n, k = kfold)
cv.tuning <- c()
for (j in cv.id){
#Split Data in train and validation sets
x.train.cv <- data.x[-j,]
y.train.cv <- data.y[-j]
x.validation.cv <- data.x[j,]
y.validation.cv <- data.y[j]
#Run Model
mod.cv <- krr(x = x.train.cv,  y.train.cv, lambda = lam)
#Estimate predictin of validation test
pred.cv <- predict(mod.cv, x.validation.cv)
#Calculate RMSE
rmse.cv <- sqrt(mean((y.validation.cv - pred.cv)^2))
cv.tuning <- cbind(cv.tuning, rmse.cv)
cv.mean <- mean(cv.tuning)
}
return(cv.mean)
}
#find a best lambda
lambdas <- c(0.7)
# lambdas <- c(0.7,0.8,0.9) #***
rmse_tune <- data.frame(lambdas=lambdas,rmse=rep(0,length(lambdas)))
for (i in 1:length(lambdas)){
m <- lapply(data_split, cv.krr, 5, lambdas[i])
rmse_tune[i,2] <-  sum(unlist(m))
}
data=data_split
k=1
lam=0.7
set.seed(123)
data
View(data_split)
tibble(data_split)
as_tibble(data_split)
data_split[1]
data=data_split[[1]]
data
set.seed(123)
data.x <- as.matrix(data[,-1])
data.y <- data[,1]
n <- nrow(data.x)
cv.id <- createFolds(1:n, k = kfold)
kfold=1
cv.id <- createFolds(1:n, k = kfold)
cv.tuning <- c()
for (j in cv.id){
#Split Data in train and validation sets
x.train.cv <- data.x[-j,]
y.train.cv <- data.y[-j]
x.validation.cv <- data.x[j,]
y.validation.cv <- data.y[j]
#Run Model
mod.cv <- krr(x = x.train.cv,  y.train.cv, lambda = lam)
#Estimate predictin of validation test
pred.cv <- predict(mod.cv, x.validation.cv)
#Calculate RMSE
rmse.cv <- sqrt(mean((y.validation.cv - pred.cv)^2))
cv.tuning <- cbind(cv.tuning, rmse.cv)
cv.mean <- mean(cv.tuning)
}
cv.id
for (j in cv.id){
#Split Data in train and validation sets
x.train.cv <- data.x[-j,]
y.train.cv <- data.y[-j]
x.validation.cv <- data.x[j,]
y.validation.cv <- data.y[j]
#Run Model
mod.cv <- krr(x = x.train.cv,  y.train.cv, lambda = lam)
#Estimate predictin of validation test
pred.cv <- predict(mod.cv, x.validation.cv)
#Calculate RMSE
rmse.cv <- sqrt(mean((y.validation.cv - pred.cv)^2))
cv.tuning <- cbind(cv.tuning, rmse.cv)
cv.mean <- mean(cv.tuning)
}
cv.id
createFolds(1:n, k = 3)
x.train.cv <- data.x[-j,]
y.train.cv <- data.y[-j]
x.validation.cv <- data.x[j,]
y.validation.cv <- data.y[j]
x.train.cv
j
kfold=2
cv.id <- createFolds(1:n, k = kfold)
cv.tuning <- c()
for (j in cv.id){
#Split Data in train and validation sets
x.train.cv <- data.x[-j,]
y.train.cv <- data.y[-j]
x.validation.cv <- data.x[j,]
y.validation.cv <- data.y[j]
#Run Model
mod.cv <- krr(x = x.train.cv,  y.train.cv, lambda = lam)
#Estimate predictin of validation test
pred.cv <- predict(mod.cv, x.validation.cv)
#Calculate RMSE
rmse.cv <- sqrt(mean((y.validation.cv - pred.cv)^2))
cv.tuning <- cbind(cv.tuning, rmse.cv)
cv.mean <- mean(cv.tuning)
}
#use tuned lambda to train 610 users model
train_model<-vector(mode="list",length=length(data_split))
for(i in 1:length(data_split)){
train_model[[i]]<-krr(data_split[[i]][,-1],data_split[[i]][,1],0.7)}
install.packages("lsa")
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(krr)
library(lsa)
library(DT)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
## We want to make sure all movieId and all userId in the in the training dataset, we do a semi-random assignment
## randomly shuffle the row of the entire dataset
shuffle.data <- data[sample(nrow(data)),]
## get a small dataset that contains all users and all movies
unique.user<-duplicated(shuffle.data[,1])
unique.movie<-duplicated(shuffle.data[,2])
index<-unique.user & unique.movie
all.user.movie <- shuffle.data[!index,]
## split the remaining data into training and testing
rest <- shuffle.data[index,]
test_idx <- sample(rownames(rest), round(nrow(shuffle.data)/5, 0))
train_idx <- setdiff(rownames(rest), test_idx)
## combine the training with the previous dataset, which has all users and all movies
data_train <- rbind(all.user.movie, shuffle.data[train_idx,])
data_test <- shuffle.data[test_idx,]
## sort the training and testing data by userId then by movieId,
## so when we update p and q, it is less likely to make mistakes
data_train <- arrange(data_train, userId, movieId)
data_test <- arrange(data_test, userId, movieId)
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
source("../lib/ALS.R1R2.R")
source("../lib/ALS.Cross.Validation.R")
f_list <- c(10, 20)
l_list <- c(5, 10, 15)
f_l <- expand.grid(f_list, l_list)
load("../output/alg.cv.rmse.Rdata")
rmse <- data.frame(rbind(t(result_summary[1,,]), t(result_summary[2,,])), train_test = rep(c("Train", "Test"), each = 6), par = rep(paste("f = ", f_l[,1], ", lambda = ", f_l[,2]), times = 2)) %>% gather("iteration", "RMSE", -train_test, -par)
rmse$iteration <- as.numeric(gsub("X", "", rmse$iteration))
rmse %>% ggplot(aes(x = iteration, y = RMSE, col = train_test)) + geom_point() + facet_wrap(~par, ncol=3)
#Parameters for f, lambda, and max iter determined from image above of 5-fold cross validation
result <- ALS.R1R2(f = 10, lambda = 10, max.iter=3, data=data, train=data_train, test=data_test)
save(result, file = "../output/mat_fac.RData")
load(file = "../output/mat_fac.RData")
cat("The train RMSE for Alternating Least Squares + Penalty of Magnitudes and Bias and Intercepts is", result$train_RMSE[3], ".\n")
cat("The test RMSE for Alternating Least Squares + Penalty of Magnitudes and Bias and Intercepts is", result$test_RMSE[3], ".\n")
source("../lib/KRR.Cross.Validation.R")
source("../lib/KRR.Postprocessing.R")
lambda=c(1, 5, 10, 15, 20)
krr.cv.rmse <- matrix(0, nrow = length(lambda), ncol = 4)
KRR.CV.Runtime <- system.time( for(i in 1:length(lambda)){
cat("lambda=", lambda[i], "\n")
krr.cv.rmse[i,] <- krr.cv (dat_train=data, K.fold=5, lambda=lambda[i])
save(krr.cv.rmse, file="../output/krr.cv.rmse.RData")
})
#Load visualization of cross validation results of KRR
load("../output/krr.cv.rmse.RData")
krr.cv.rmse <- as.data.frame(krr.cv.rmse)
colnames(krr.cv.rmse) <- c("mean_train_rmse", "mean_test_rmse", "sd_train_rmse", "sd_test_rmse")
lambda=c(1,5,10,15,20)
krr.cv.rmse$lambda = as.factor(lambda)
krr.cv.rmse %>%
ggplot(aes(x = lambda, y = mean_test_rmse,
ymin = mean_test_rmse - sd_test_rmse, ymax = mean_test_rmse + sd_test_rmse)) +
geom_crossbar() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
source("../lib/KRR.Postprocessing.R")
KRR.result <- KRR.Post(lambda = 5, data=data, train = data_train, test=data_test)
save(KRR.result, file = "../output/KRR.result.RData")
data
data_train
data_test
load("../output/KRR.result.RData")
cat("The train RMSE for SVD with Kernel Ridge Regression is", KRR.result$train_RMSE, ".\n")
cat("The test RMSE SVD with Kernel Ridge Regression is", KRR.result$test_RMSE, ".\n")
data_train$krr.pred <- apply(data_train, 1, get.pred, est_rating=KRR.result$krr.rating)
load("../output/KNN.result.RData")
source("../lib/Getting.pred.R")
data_train$krr.pred <- apply(data_train, 1, get.pred, est_rating=KRR.result$krr.rating)
data_test$krr.pred <- apply(data_test, 1, get.pred, est_rating=KRR.result$krr.rating)
## fit linear model
als.krr.model <- lm(rating ~ als.pred+krr.pred, data=data_train)
source("../lib/ALS.R1R2.R")
source("../lib/ALS.Cross.Validation.R")
# load(file = "../output/similarity.matrix.Rdata")
source("../lib/KNN.Postprocessing.R")
source("../lib/Getting.pred.R")
source("../lib/KRR.Cross.Validation.R")
source("../lib/KRR.Postprocessing.R")
source("../lib/KRR.Postprocessing.R")
## fit linear model
als.krr.model <- lm(rating ~ als.pred+krr.pred, data=data_train)
## fit linear model
als.knn.model <- lm(rating ~ als.pred+knn.pred, data=data_train)
data_train$als.pred <- apply(data_train, 1, get.pred, est_rating=result$ALS.rating)
data_train$knn.pred <- apply(data_train, 1, get.pred, est_rating=KNN.result$knn.rating)
data_train$krr.pred <- apply(data_train, 1, get.pred, est_rating=KRR.result$krr.rating)
data_test$krr.pred <- apply(data_test, 1, get.pred, est_rating=KRR.result$krr.rating)
## fit linear model
als.krr.model <- lm(rating ~ als.pred+krr.pred, data=data_train)
## get training prediction
als.krr.train <- predict(als.krr.model, data_train[,c(5,7)])
View(data_train)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
source("../lib/P3.r")
load("../output/mat_fac_A2.RData")
source("../lib/P3.R")
load("../output/mat_fac_A2.RData")
mat_fac_A2
xx=load("../output/mat_fac_A2.RData")
library(dplyr)
library(tidyr)
source("../lib/P3.R")
load("../output/mat_fac_A2.RData")
library(tidyverse)
library(caret)
library(parallel)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(1)
# train-test split (.8/.2)
train_ind <- createDataPartition(data$userId, p=.8, list=F)
train <- data[train_ind, ]
test <- data[-train_ind, ]
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
minFunc <- function(rating, matSolv, lambda){
solve(matSolv %*% t(matSolv) + lambda * diag(f)) %*% matSolv %*% rating
}
# The Function used to Find the
findSolve <- function(id, solveBy, train, lambda){
id <- as.integer(id)
# Fix Movies, solve User
if(solveBy=="Movies"){
movId <- train[train$userId==id, ]$movieId
movSolv <- Movies[, as.character(movId)]
rating <- train[train$userId==id, ]$rating
minFunc(rating = rating, matSolv = movSolv, lambda = lambda)
}
# Fix User, solve Movie
else if(solveBy=="Users"){
userId <- train[train$movieId==id, ]$userId
userSolv <- Users[, as.character(userId)]
rating <- train[train$movieId==id, ]$rating
minFunc(rating = rating, matSolv = userSolv, lambda = lambda)
}
else return("Please let matSolv be in right way")
}
ALS <- function(data, train, test, f, maxIters, lambda=5){
# Factorized the Movies and User matrices
UserId <- unique(data$userId)
U <- length(UserId)
MovieId <- unique(data$movieId)
M <- length(MovieId)
avgRatingByUser <- data %>%
group_by(userId) %>%
summarise(avgRating = mean(rating))
avgRatingByMovie <- data %>%
group_by(movieId) %>%
summarise(avgRating = mean(rating))
Users <- matrix(c(avgRatingByUser$avgRating, runif((f-1)*U, -1, 1)), nrow=f, byrow = T)
colnames(Users) <- UserId
Movies <- matrix(c(avgRatingByMovie$avgRating, rnorm((f-1)*M, -1, 1)), nrow=f, byrow = T)
colnames(Movies) <- MovieId
clusterExport(cl, "minFunc", envir = environment())
clusterExport(cl, "f", envir = environment())
clusterExport(cl, "UserId", envir = environment())
clusterExport(cl, "MovieId", envir = environment())
trainRMSE <- rep(NA, maxIters%/%3)
testRMSE <- rep(NA, maxIters%/%3)
iter <- 1
while(iter <= maxIters){
st <- Sys.time()
# Fix Movie, solve User
clusterExport(cl, "Movies", envir = environment())
clusterExport(cl, "Users", envir = environment())
Users <- parSapply(cl, as.character(UserId), findSolve, solveBy="Movies", train = train, lambda = lambda, USE.NAMES = T)
# Fix User, solve Movie
clusterExport(cl, "Movies", envir = environment())
clusterExport(cl, "Users", envir = environment())
Movies <- parSapply(cl, as.character(MovieId), findSolve, solveBy="Users", train = train, lambda = lambda, USE.NAMES = T)
# cat("Iter:", iter,  "\t Time spent:", round(Sys.time()-st, 3), "s\n")
if(iter%%3==1){
est_rating <- t(Users) %*% Movies
trainRMSE[iter%/%3+1] <- RMSE(train, est_rating)
testRMSE[iter%/%3+1] <- RMSE(test, est_rating)
}
cat(".")
if(iter==maxIters) cat("\n")
iter <- iter + 1
}
# RMSE
# est_rating <- t(Users) %*% Movies
# trainRMSE <- RMSE(train, est_rating)
# testRMSE <- RMSE(test, est_rating)
return(list("User" = Users,
"Movie" = Movies,
"Rating" = est_rating,
"TrainRMSE" = trainRMSE,
"TestRMSE" = testRMSE))
}
resultALS <- ALS(data, train, test, f = 5, maxIters =10 , lambda =5)
# set the number of cores to use
cl <- makeCluster(4)
resultALS <- ALS(data, train, test, f = 5, maxIters =10 , lambda =5)
save(resultALS, file = "../output/resultALS.RData")
load(file = "../output/resultALS.RData")
source("../lib/P3.R")
library(dplyr)
library(tidyr)
result_A2=resultALS
result_A2=resultALS
# load("../output/mat_fac_A2.RData")
result_A2=resultALS
# rating = t(result_A2$p) %*% result_A2$q
rating =result_A2$Rating
X = X_mat(result_A2$Movie)
n = nrow(X)
lamb = 0.5
I = diag(n)
# SVD_KRR
svd_krr_pred_rating <- K(X,X) %*% solve((K(X,X)+lamb*I)) %*% t(rating)
K(X,X)
load("../output/mat_fac_A2.RData")
result_A2$p%>%dim
resultALS$Movie%>%dim
result_A2$q%>%dim
rating = t(result_A2$p) %*% result_A2$q
rating =result_A2$Rating
X = X_mat(result_A2$q)
n = nrow(X)
lamb = 0.5
I = diag(n)
# SVD_KRR
svd_krr_pred_rating <- K(X,X) %*% solve((K(X,X)+lamb*I)) %*% t(rating)
memory.limit()
memory.limit(1000000)
memory.limit(100000)
memory.limit(10000)
memory.limit(1000)
memory.limit()
rm(list=ls())
