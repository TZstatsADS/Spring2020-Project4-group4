rmse.cv <- sqrt(mean((y.validation.cv - pred.cv)^2))
cv.tuning <- cbind(cv.tuning, rmse.cv)
cv.mean <- mean(cv.tuning)
}
cv.id
for (j in cv.id){
#Split Data in train and validation sets
x.train.cv <- data.x[-j,]
y.train.cv <- data.y[-j]
x.validation.cv <- data.x[j,]
y.validation.cv <- data.y[j]
#Run Model
mod.cv <- krr(x = x.train.cv,  y.train.cv, lambda = lam)
#Estimate predictin of validation test
pred.cv <- predict(mod.cv, x.validation.cv)
#Calculate RMSE
rmse.cv <- sqrt(mean((y.validation.cv - pred.cv)^2))
cv.tuning <- cbind(cv.tuning, rmse.cv)
cv.mean <- mean(cv.tuning)
}
cv.id
createFolds(1:n, k = 3)
x.train.cv <- data.x[-j,]
y.train.cv <- data.y[-j]
x.validation.cv <- data.x[j,]
y.validation.cv <- data.y[j]
x.train.cv
j
kfold=2
cv.id <- createFolds(1:n, k = kfold)
cv.tuning <- c()
for (j in cv.id){
#Split Data in train and validation sets
x.train.cv <- data.x[-j,]
y.train.cv <- data.y[-j]
x.validation.cv <- data.x[j,]
y.validation.cv <- data.y[j]
#Run Model
mod.cv <- krr(x = x.train.cv,  y.train.cv, lambda = lam)
#Estimate predictin of validation test
pred.cv <- predict(mod.cv, x.validation.cv)
#Calculate RMSE
rmse.cv <- sqrt(mean((y.validation.cv - pred.cv)^2))
cv.tuning <- cbind(cv.tuning, rmse.cv)
cv.mean <- mean(cv.tuning)
}
#use tuned lambda to train 610 users model
train_model<-vector(mode="list",length=length(data_split))
for(i in 1:length(data_split)){
train_model[[i]]<-krr(data_split[[i]][,-1],data_split[[i]][,1],0.7)}
install.packages("lsa")
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(krr)
library(lsa)
library(DT)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
## We want to make sure all movieId and all userId in the in the training dataset, we do a semi-random assignment
## randomly shuffle the row of the entire dataset
shuffle.data <- data[sample(nrow(data)),]
## get a small dataset that contains all users and all movies
unique.user<-duplicated(shuffle.data[,1])
unique.movie<-duplicated(shuffle.data[,2])
index<-unique.user & unique.movie
all.user.movie <- shuffle.data[!index,]
## split the remaining data into training and testing
rest <- shuffle.data[index,]
test_idx <- sample(rownames(rest), round(nrow(shuffle.data)/5, 0))
train_idx <- setdiff(rownames(rest), test_idx)
## combine the training with the previous dataset, which has all users and all movies
data_train <- rbind(all.user.movie, shuffle.data[train_idx,])
data_test <- shuffle.data[test_idx,]
## sort the training and testing data by userId then by movieId,
## so when we update p and q, it is less likely to make mistakes
data_train <- arrange(data_train, userId, movieId)
data_test <- arrange(data_test, userId, movieId)
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
source("../lib/ALS.R1R2.R")
source("../lib/ALS.Cross.Validation.R")
f_list <- c(10, 20)
l_list <- c(5, 10, 15)
f_l <- expand.grid(f_list, l_list)
load("../output/alg.cv.rmse.Rdata")
rmse <- data.frame(rbind(t(result_summary[1,,]), t(result_summary[2,,])), train_test = rep(c("Train", "Test"), each = 6), par = rep(paste("f = ", f_l[,1], ", lambda = ", f_l[,2]), times = 2)) %>% gather("iteration", "RMSE", -train_test, -par)
rmse$iteration <- as.numeric(gsub("X", "", rmse$iteration))
rmse %>% ggplot(aes(x = iteration, y = RMSE, col = train_test)) + geom_point() + facet_wrap(~par, ncol=3)
#Parameters for f, lambda, and max iter determined from image above of 5-fold cross validation
result <- ALS.R1R2(f = 10, lambda = 10, max.iter=3, data=data, train=data_train, test=data_test)
save(result, file = "../output/mat_fac.RData")
load(file = "../output/mat_fac.RData")
cat("The train RMSE for Alternating Least Squares + Penalty of Magnitudes and Bias and Intercepts is", result$train_RMSE[3], ".\n")
cat("The test RMSE for Alternating Least Squares + Penalty of Magnitudes and Bias and Intercepts is", result$test_RMSE[3], ".\n")
source("../lib/KRR.Cross.Validation.R")
source("../lib/KRR.Postprocessing.R")
lambda=c(1, 5, 10, 15, 20)
krr.cv.rmse <- matrix(0, nrow = length(lambda), ncol = 4)
KRR.CV.Runtime <- system.time( for(i in 1:length(lambda)){
cat("lambda=", lambda[i], "\n")
krr.cv.rmse[i,] <- krr.cv (dat_train=data, K.fold=5, lambda=lambda[i])
save(krr.cv.rmse, file="../output/krr.cv.rmse.RData")
})
#Load visualization of cross validation results of KRR
load("../output/krr.cv.rmse.RData")
krr.cv.rmse <- as.data.frame(krr.cv.rmse)
colnames(krr.cv.rmse) <- c("mean_train_rmse", "mean_test_rmse", "sd_train_rmse", "sd_test_rmse")
lambda=c(1,5,10,15,20)
krr.cv.rmse$lambda = as.factor(lambda)
krr.cv.rmse %>%
ggplot(aes(x = lambda, y = mean_test_rmse,
ymin = mean_test_rmse - sd_test_rmse, ymax = mean_test_rmse + sd_test_rmse)) +
geom_crossbar() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
source("../lib/KRR.Postprocessing.R")
KRR.result <- KRR.Post(lambda = 5, data=data, train = data_train, test=data_test)
save(KRR.result, file = "../output/KRR.result.RData")
data
data_train
data_test
load("../output/KRR.result.RData")
cat("The train RMSE for SVD with Kernel Ridge Regression is", KRR.result$train_RMSE, ".\n")
cat("The test RMSE SVD with Kernel Ridge Regression is", KRR.result$test_RMSE, ".\n")
data_train$krr.pred <- apply(data_train, 1, get.pred, est_rating=KRR.result$krr.rating)
load("../output/KNN.result.RData")
source("../lib/Getting.pred.R")
data_train$krr.pred <- apply(data_train, 1, get.pred, est_rating=KRR.result$krr.rating)
data_test$krr.pred <- apply(data_test, 1, get.pred, est_rating=KRR.result$krr.rating)
## fit linear model
als.krr.model <- lm(rating ~ als.pred+krr.pred, data=data_train)
source("../lib/ALS.R1R2.R")
source("../lib/ALS.Cross.Validation.R")
# load(file = "../output/similarity.matrix.Rdata")
source("../lib/KNN.Postprocessing.R")
source("../lib/Getting.pred.R")
source("../lib/KRR.Cross.Validation.R")
source("../lib/KRR.Postprocessing.R")
source("../lib/KRR.Postprocessing.R")
## fit linear model
als.krr.model <- lm(rating ~ als.pred+krr.pred, data=data_train)
## fit linear model
als.knn.model <- lm(rating ~ als.pred+knn.pred, data=data_train)
data_train$als.pred <- apply(data_train, 1, get.pred, est_rating=result$ALS.rating)
data_train$knn.pred <- apply(data_train, 1, get.pred, est_rating=KNN.result$knn.rating)
data_train$krr.pred <- apply(data_train, 1, get.pred, est_rating=KRR.result$krr.rating)
data_test$krr.pred <- apply(data_test, 1, get.pred, est_rating=KRR.result$krr.rating)
## fit linear model
als.krr.model <- lm(rating ~ als.pred+krr.pred, data=data_train)
## get training prediction
als.krr.train <- predict(als.krr.model, data_train[,c(5,7)])
View(data_train)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
source("../lib/P3.r")
load("../output/mat_fac_A2.RData")
source("../lib/P3.R")
load("../output/mat_fac_A2.RData")
mat_fac_A2
xx=load("../output/mat_fac_A2.RData")
library(dplyr)
library(tidyr)
source("../lib/P3.R")
load("../output/mat_fac_A2.RData")
library(tidyverse)
library(caret)
library(parallel)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(1)
# train-test split (.8/.2)
train_ind <- createDataPartition(data$userId, p=.8, list=F)
train <- data[train_ind, ]
test <- data[-train_ind, ]
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
minFunc <- function(rating, matSolv, lambda){
solve(matSolv %*% t(matSolv) + lambda * diag(f)) %*% matSolv %*% rating
}
# The Function used to Find the
findSolve <- function(id, solveBy, train, lambda){
id <- as.integer(id)
# Fix Movies, solve User
if(solveBy=="Movies"){
movId <- train[train$userId==id, ]$movieId
movSolv <- Movies[, as.character(movId)]
rating <- train[train$userId==id, ]$rating
minFunc(rating = rating, matSolv = movSolv, lambda = lambda)
}
# Fix User, solve Movie
else if(solveBy=="Users"){
userId <- train[train$movieId==id, ]$userId
userSolv <- Users[, as.character(userId)]
rating <- train[train$movieId==id, ]$rating
minFunc(rating = rating, matSolv = userSolv, lambda = lambda)
}
else return("Please let matSolv be in right way")
}
ALS <- function(data, train, test, f, maxIters, lambda=5){
# Factorized the Movies and User matrices
UserId <- unique(data$userId)
U <- length(UserId)
MovieId <- unique(data$movieId)
M <- length(MovieId)
avgRatingByUser <- data %>%
group_by(userId) %>%
summarise(avgRating = mean(rating))
avgRatingByMovie <- data %>%
group_by(movieId) %>%
summarise(avgRating = mean(rating))
Users <- matrix(c(avgRatingByUser$avgRating, runif((f-1)*U, -1, 1)), nrow=f, byrow = T)
colnames(Users) <- UserId
Movies <- matrix(c(avgRatingByMovie$avgRating, rnorm((f-1)*M, -1, 1)), nrow=f, byrow = T)
colnames(Movies) <- MovieId
clusterExport(cl, "minFunc", envir = environment())
clusterExport(cl, "f", envir = environment())
clusterExport(cl, "UserId", envir = environment())
clusterExport(cl, "MovieId", envir = environment())
trainRMSE <- rep(NA, maxIters%/%3)
testRMSE <- rep(NA, maxIters%/%3)
iter <- 1
while(iter <= maxIters){
st <- Sys.time()
# Fix Movie, solve User
clusterExport(cl, "Movies", envir = environment())
clusterExport(cl, "Users", envir = environment())
Users <- parSapply(cl, as.character(UserId), findSolve, solveBy="Movies", train = train, lambda = lambda, USE.NAMES = T)
# Fix User, solve Movie
clusterExport(cl, "Movies", envir = environment())
clusterExport(cl, "Users", envir = environment())
Movies <- parSapply(cl, as.character(MovieId), findSolve, solveBy="Users", train = train, lambda = lambda, USE.NAMES = T)
# cat("Iter:", iter,  "\t Time spent:", round(Sys.time()-st, 3), "s\n")
if(iter%%3==1){
est_rating <- t(Users) %*% Movies
trainRMSE[iter%/%3+1] <- RMSE(train, est_rating)
testRMSE[iter%/%3+1] <- RMSE(test, est_rating)
}
cat(".")
if(iter==maxIters) cat("\n")
iter <- iter + 1
}
# RMSE
# est_rating <- t(Users) %*% Movies
# trainRMSE <- RMSE(train, est_rating)
# testRMSE <- RMSE(test, est_rating)
return(list("User" = Users,
"Movie" = Movies,
"Rating" = est_rating,
"TrainRMSE" = trainRMSE,
"TestRMSE" = testRMSE))
}
resultALS <- ALS(data, train, test, f = 5, maxIters =10 , lambda =5)
# set the number of cores to use
cl <- makeCluster(4)
resultALS <- ALS(data, train, test, f = 5, maxIters =10 , lambda =5)
save(resultALS, file = "../output/resultALS.RData")
load(file = "../output/resultALS.RData")
source("../lib/P3.R")
library(dplyr)
library(tidyr)
result_A2=resultALS
result_A2=resultALS
# load("../output/mat_fac_A2.RData")
result_A2=resultALS
# rating = t(result_A2$p) %*% result_A2$q
rating =result_A2$Rating
X = X_mat(result_A2$Movie)
n = nrow(X)
lamb = 0.5
I = diag(n)
# SVD_KRR
svd_krr_pred_rating <- K(X,X) %*% solve((K(X,X)+lamb*I)) %*% t(rating)
K(X,X)
load("../output/mat_fac_A2.RData")
result_A2$p%>%dim
resultALS$Movie%>%dim
result_A2$q%>%dim
rating = t(result_A2$p) %*% result_A2$q
rating =result_A2$Rating
X = X_mat(result_A2$q)
n = nrow(X)
lamb = 0.5
I = diag(n)
# SVD_KRR
svd_krr_pred_rating <- K(X,X) %*% solve((K(X,X)+lamb*I)) %*% t(rating)
memory.limit()
memory.limit(1000000)
memory.limit(100000)
memory.limit(10000)
memory.limit(1000)
memory.limit()
rm(list=ls())
load(file = "../output/rmse.Rdata")
result_summary
result_summary
library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
source("../lib/Matrix_Factorization.R")
source("../lib/cross_validation.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
f_l
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
f_l
result_summary
f_l
result_summary[,,1]
library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
source("../lib/Matrix_Factorization.R")
source("../lib/cross_validation.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
i=1
K=2
cv.function(data, K = K, f = f_l[i,1], lambda = 10^f_l[i,2])
source("../lib/cross_validation.R")
cv.function <- function(dat_train, K, f, lambda){
### Input:
### - train data frame
### - K: a number stands for K-fold CV
### - tuning parameters
n <- dim(dat_train)[1]
n.fold <- round(n/K, 0)
set.seed(0)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
train_rmse <- matrix(NA, ncol = 10,nrow = K)
test_rmse <- matrix(NA, ncol = 10, nrow = K)
for (i in 1:K){
train.data <- dat_train[s != i,]
test.data <- dat_train[s == i,]
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 100, stopping.deriv = 0.01,
data = dat_train, train = train.data, test = test.data)
train_rmse[i,] <-  result$train_rmse
test_rmse[i,] <-   result$test_rmse
}
return(list(mean_train_rmse = apply(train_rmse, 2, mean), mean_test_rmse = apply(test_rmse, 2, mean),
sd_train_rmse = apply(train_rmse, 2, sd), sd_test_rmse = apply(test_rmse, 2, sd)))
}
cv.function(data, K = K, f = f_l[i,1], lambda = 10^f_l[i,2])
data%>%dim
dat_train=data
n <- dim(dat_train)[1]
n.fold <- round(n/K, 0)
set.seed(0)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
train_rmse <- matrix(NA, ncol = 10,nrow = K)
test_rmse <- matrix(NA, ncol = 10, nrow = K)
i=1
train.data <- dat_train[s != i,]
test.data <- dat_train[s == i,]
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 5, stopping.deriv = 0.01,
data = dat_train, train = train.data, test = test.data)
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 5, stopping.deriv = 0.01,
data = dat_train, train = train.data, test = test.data)
f = f_l[i,1]
lambda = 10^f_l[i,2]
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 5, stopping.deriv = 0.01,
data = dat_train, train = train.data, test = test.data)
data%>%dim
data=data[1:100,]
dat_train=data
n <- dim(dat_train)[1]
n.fold <- round(n/K, 0)
set.seed(0)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
train_rmse <- matrix(NA, ncol = 10,nrow = K)
test_rmse <- matrix(NA, ncol = 10, nrow = K)
i=1
train.data <- dat_train[s != i,]
test.data <- dat_train[s == i,]
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 5, stopping.deriv = 0.01,
data = dat_train, train = train.data, test = test.data)
f
lambda
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 5, stopping.deriv = 0.01,
data = dat_train, train = train.data, test = test.data)
dat_train%>%dim
data%>%dim
library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
load("../output/rmse.Rdata")
rmse <- data.frame(rbind(t(result_summary[1,,]), t(result_summary[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse$epoch <- as.numeric(gsub("X", "", rmse$epoch))
rmse %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
rmse
result_summary
result_summary[1,,]
result_summary[3,,]
rbind(t(result_summary[1,,]), t(result_summary[2,,]))
result_summary%>%dim
result_summary[1,,]
t(result_summary[1,,])
rbind(t(result_summary[1,,]), t(result_summary[2,,])
)
library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
source("../lib/Matrix_Factorization.R")
source("../lib/cross_validation.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
data%>%dim
n <- dim(dat_train)[1]
n.fold <- round(n/K, 0)
set.seed(0)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
train_rmse <- matrix(NA, ncol = 10,nrow = K)
test_rmse <- matrix(NA, ncol = 10, nrow = K)
K
lambda
lambda=1
f
for (i in 1:K){
train.data <- dat_train[s != i,]
test.data <- dat_train[s == i,]
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 5, stopping.deriv = 5,
data = dat_train, train = train.data, test = test.data)
train_rmse[i,] <-  result$train_rmse
test_rmse[i,] <-   result$test_rmse
}
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 10, stopping.deriv = 5,
data = dat_train, train = train.data, test = test.data)
for (i in 1:K){
train.data <- dat_train[s != i,]
test.data <- dat_train[s == i,]
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 100, stopping.deriv = 5,
data = dat_train, train = train.data, test = test.data)
train_rmse[i,] <-  result$train_rmse
test_rmse[i,] <-   result$test_rmse
}
for (i in 1:K){
train.data <- dat_train[s != i,]
test.data <- dat_train[s == i,]
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 100, stopping.deriv = 0.01,
data = dat_train, train = train.data, test = test.data)
train_rmse[i,] <-  result$train_rmse
test_rmse[i,] <-   result$test_rmse
}
data.frame(rbind(t(result_summary[1,,]),
t(result_summary[2,,])),
train_test = rep(c("Train", "Test"), each = 4),
par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2))
result_summary[,,1]
data.frame(rbind(t(result_summary[1,,]),
t(result_summary[2,,])),
train_test = rep(c("Train", "Test"), each = 4),
par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
data.frame(rbind(t(result_summary[1,,]),
t(result_summary[2,,])),
train_test = rep(c("Train", "Test"), each = 4),
par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2))
f_l
rmse
data.frame(rbind(t(result_summary[1,,]),
t(result_summary[2,,])),
train_test = rep(c("Train", "Test"), each = 4),
par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2))
