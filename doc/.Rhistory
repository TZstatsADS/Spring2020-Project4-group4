library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
?gradesc
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
source("../lib/Matrix_Factorization.R")
source("../lib/cross_validation.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
result_summary <- array(NA, dim = c(nrow(f_l), 10, 4))
run_time <- system.time(for(i in 1:nrow(f_l)){
par <- paste("f = ", f_l[i,1], ", lambda = ", 10^f_l[i,2])
cat(par, "\n")
current_result <- cv.function(data, K = 5, f = f_l[i,1], lambda = 10^f_l[i,2])
result_summary[,,i] <- matrix(unlist(current_result), ncol = 10, byrow = T)
print(result_summary)
})
nrow(f_l)
i=1
par <- paste("f = ", f_l[i,1], ", lambda = ", 10^f_l[i,2])
cat(par, "\n")
current_result <- cv.function(data, K = 5, f = f_l[i,1], lambda = 10^f_l[i,2])
K = 5
f = f_l[i,1]
lambda = 10^f_l[i,2]
dat_train=data
n <- dim(dat_train)[1]
n.fold <- round(n/K, 0)
set.seed(0)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
train_rmse <- matrix(NA, ncol = 10,nrow = K)
test_rmse <- matrix(NA, ncol = 10, nrow = K)
i=1
train.data <- dat_train[s != i,]
test.data <- dat_train[s == i,]
result <- gradesc(f = f, lambda =lambda,
lrate = 0.01, max.iter = 100, stopping.deriv = 0.01,
data = dat_train, train = train.data, test = test.data)
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(cache = T)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
# options(mc.cores = parallel::detectCores())
library(dplyr)
library(tidyr)
library(ggplot2)
library(anytime)
data <- read.csv("../data/ml-latest-small/ratings.csv")
data <- read.csv("../data/ml-latest-small/ratings.csv")
data$timestamp <- anydate(data$timestamp)
data <- data %>%
group_by(userId) %>%
mutate(timediff = (timestamp - mean(timestamp)) %>% as.numeric) %>%
ungroup() %>%
arrange(timestamp)
data$timestamp <- anydate(data$timestamp)
data <- data %>%
group_by(userId) %>%
mutate(timediff = (timestamp - mean(timestamp)) %>% as.numeric) %>%
ungroup() %>%
arrange(timestamp)
set.seed(0)
## shuffle the row of the entire dataset
data <- data[sample(nrow(data)),]
## get a small dataset that contains all users and all movies
unique.user<-duplicated(data[,1])
unique.movie<-duplicated(data[,2])
index<-unique.user & unique.movie
all.user.movie <- data[!index,]
## split training and test on the rest
rest <- data[index,]
test_idx <- sample(rownames(rest), round(nrow(data)/5, 0))
train_idx <- setdiff(rownames(rest), test_idx)
## combine the training with the previous dataset, which has all users and all movies
data_train <- rbind(all.user.movie, data[train_idx,])
data_test <- data[test_idx,]
## sort the training and testing data by userId then by movieId,
## so when we update p and q, it is less likely to make mistakes
data_train <- arrange(data_train, userId, movieId)
data_test <- arrange(data_test, userId, movieId)
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
RMSE <- function(rating, est_rating) {
error <- rep(NA, nrow(rating))
for (i in 1:nrow(rating)) {
a <- as.character(rating[i,1])
b <-as.character(rating[i,2])
error[i] <- (rating[i,3]-est_rating[a, b])^2
}
error = error %>% unlist()
return(sqrt(mean(error)))
}
